{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идеальное решение на основе предыдущих экспериментов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из ноутбука удалены лишние строки по анализу данных и прошлых экспериментов\n",
    "чтобы уменьшить время выполнения ноутбука да и вообще самому легче ориентироваться в коротком ноутбуке\n",
    "\n",
    "Использовать **ImageDataAugmentor** не получилось, постоянно возникали какие-то непонятные ошибки, решил настраивать генерацию руками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python       : 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print('Python       :', sys.version.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow --upgrade\n",
    "!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "import keras as keras\n",
    "import keras.models\n",
    "import keras.layers\n",
    "import keras.backend\n",
    "import keras.callbacks\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageOps, ImageFilter\n",
    "#увеличим дефолтный размер графиков\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "#графики в svg выглядят более четкими\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "%matplotlib inline\n",
    "\n",
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)\n",
    "print('Tensorflow   :', tf.__version__)\n",
    "print('Keras        :', tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_list = device_lib.list_local_devices()\n",
    "device_list_GPU = [x.name for x in device_list if 'GPU' in x.name]\n",
    "print ('GPU подключен') if device_list_GPU else  print('GPU не подключен')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH  = '../input/sf-dl-car-classification/'\n",
    "MODELS_PATH = '../input/models/'\n",
    "OUTPUT_PATH = '../working/car/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_PATH, exist_ok = True)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA / Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -d -r '/dev/shm/'\n",
    "#!rm -d -r '../working/car/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip '../input/sf-dl-car-classification/train.zip' -d /dev/shm/\n",
    "#!unzip '../input/sf-dl-car-classification/train.zip' -d '../working/car/'\n",
    "print('Распаковка картинок')\n",
    "with zipfile.ZipFile(INPUT_PATH + 'train.zip',\"r\") as z:\n",
    "    z.extractall(OUTPUT_PATH)\n",
    "print('Распаковка завершена')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(INPUT_PATH + 'train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify Split не удался, решил ограничиться разделением в ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для размера 380 и EfficientNetB4 получаем на последнем этапе ошибку 'OOM when allocating tensor ... by allocator GPU_0_bfc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS               = 6\n",
    "BATCH_SIZE           = 16\n",
    "LR                   = 1e-3\n",
    "VALID_SPLIT          = 0.3\n",
    "\n",
    "CLASS_NUM            = 10\n",
    "IMG_SIZE             = 260\n",
    "IMG_CHANNELS         = 3\n",
    "input_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
    "\n",
    "USE_BIAS             = False\n",
    "KERNEL_REG           = 'l2'\n",
    "DROPOUT_RATE         = 0.25\n",
    "EPOCHS_DROP          = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rescale = 1. / 255\n",
    "p_rotation_range = 5\n",
    "p_zoom_range = 0.1\n",
    "p_width_shift_range = 0.1\n",
    "p_height_shift_range = 0.1\n",
    "p_brightness_range = [0.5, 0.1]\n",
    "p_shear_range = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = p_rescale,\n",
    "    zoom_range = p_zoom_range,\n",
    "    rotation_range = p_rotation_range,\n",
    "    width_shift_range = p_width_shift_range,\n",
    "    height_shift_range = p_height_shift_range,\n",
    "    shear_range = p_shear_range,\n",
    "    validation_split = VALID_SPLIT,\n",
    "    horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators():\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        OUTPUT_PATH + 'train/',\n",
    "        target_size = (IMG_SIZE, IMG_SIZE),\n",
    "        batch_size = BATCH_SIZE,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True, \n",
    "        seed = RANDOM_SEED,\n",
    "        subset = 'training')\n",
    "\n",
    "    valid_generator = train_datagen.flow_from_directory(\n",
    "        OUTPUT_PATH +'train/',\n",
    "        target_size = (IMG_SIZE, IMG_SIZE),\n",
    "        batch_size = BATCH_SIZE,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True, \n",
    "        seed = RANDOM_SEED,\n",
    "        subset = 'validation')\n",
    "    return train_generator, valid_generator\n",
    "\n",
    "train_generator, valid_generator = create_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = Xception(weights = 'imagenet', include_top = False, input_shape = input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape = input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для размера 260 используем EfficientNetB2\n",
    "base_model = efn.EfficientNetB2(weights = 'imagenet', include_top = False, input_shape = input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замораживаем веса в базовой модели\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Устанавливаем новую \"голову\" (head)\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D()) # объединяем все признаки в единый вектор \n",
    "\n",
    "    model.add(Dense(IMG_SIZE, use_bias = USE_BIAS, kernel_regularizer = KERNEL_REG, activation = 'relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(CLASS_NUM, activation = 'softmax'))\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_callbacks():\n",
    "    checkpoint = ModelCheckpoint('best_model.hdf5', monitor = 'val_accuracy', verbose = 1, mode = 'max', save_best_only = True)\n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0, verbose = 1, patience = 3, restore_best_weights = True)    \n",
    "    def scheduler(epoch):\n",
    "        return LR * math.pow(math.exp(-0.1), math.floor((1 + epoch) / EPOCHS_DROP))\n",
    "    lrScheduler = LearningRateScheduler(scheduler, verbose = 1)\n",
    "    #reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.25, patience = 3, min_lr = 0.0000001, verbose = 1, mode = 'auto')\n",
    "    \n",
    "    #tbCallBack = keras.callbacks.TensorBoard(log_dir = OUTPUT_PATH + 'logs/', histogram_freq = 0, write_graph = True, write_images = False)\n",
    "    \n",
    "    return [checkpoint, earlystop, lrScheduler]\n",
    "\n",
    "callbacks_list = create_callbacks()\n",
    "\n",
    "def build_and_fit_model(need_load = False, step_number = ''):    \n",
    "    model = create_model()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr = LR, amsgrad = True), metrics = [\"accuracy\"])   \n",
    "    history = []\n",
    "    if need_load:\n",
    "        model.load_weights(MODELS_PATH + f'best_model_step_{step_number}.hdf5')\n",
    "    else:        \n",
    "        history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch = len(train_generator),\n",
    "            validation_data = valid_generator, \n",
    "            validation_steps = len(valid_generator),\n",
    "            epochs = EPOCHS,\n",
    "            callbacks = callbacks_list\n",
    "        )\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, model = build_and_fit_model(False, step_number = '1')\n",
    "\n",
    "model.save('../working/best_model_step_1.hdf5')\n",
    "\n",
    "model.load_weights('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def calc_scores():\n",
    "    return model.evaluate_generator(valid_generator, steps = len(valid_generator), verbose = 1)\n",
    "\n",
    "scores = calc_scores()\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_fig():\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_fig = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs_fig, acc, 'g', label = 'Training acc')\n",
    "    plt.plot(epochs_fig, val_acc, 'r', label = 'Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs_fig, loss, 'g', label = 'Training loss')\n",
    "    plt.plot(epochs_fig, val_loss, 'r', label = 'Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "draw_fig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 8\n",
    "LR     = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "# Замораживаем половину базовой модели\n",
    "fine_tune_at = len(base_model.layers) // 2\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, model = build_and_fit_model()\n",
    "\n",
    "model.save('../working/best_model_step_2.hdf5')\n",
    "\n",
    "model.load_weights('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = calc_scores()\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_fig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "LR     = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размораживаем всю базовую модель\n",
    "for layer in base_model.layers:\n",
    "    if not isinstance(layer, BatchNormalization): \n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, model = build_and_fit_model()\n",
    "\n",
    "model.save('../working/best_model_step_3.hdf5')\n",
    "\n",
    "model.load_weights('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = calc_scores()\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_fig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip '../input/sf-dl-car-classification/test.zip' -d '../working/car/'\n",
    "print('Распаковка картинок')\n",
    "with zipfile.ZipFile(INPUT_PATH + 'test.zip',\"r\") as z:\n",
    "    z.extractall(OUTPUT_PATH)\n",
    "print('Распаковка завершена')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(INPUT_PATH + 'sample-submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = p_rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = submission_df,\n",
    "    directory = OUTPUT_PATH + 'test_upload/',\n",
    "    x_col = 'Id',\n",
    "    y_col = None,\n",
    "    shuffle = False,\n",
    "    class_mode = None,\n",
    "    seed = RANDOM_SEED,\n",
    "    target_size = (IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "predictions = model.predict_generator(test_generator, steps=len(test_generator), verbose=1) \n",
    "predictions = np.argmax(predictions, axis = -1) #multiple categories\n",
    "label_map = (train_generator.class_indices)\n",
    "label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
    "predictions = [label_map[k] for k in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_dir = test_generator.filenames\n",
    "submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns = ['Id', 'Category'])\n",
    "submission['Id'] = submission['Id'].replace('test_upload/','')\n",
    "submission.to_csv('submission.csv', index = False)\n",
    "print('Save submit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = p_rescale,\n",
    "    zoom_range = p_zoom_range,\n",
    "    rotation_range = p_rotation_range,\n",
    "    width_shift_range = p_width_shift_range,\n",
    "    height_shift_range = p_height_shift_range,\n",
    "    shear_range = p_shear_range,    \n",
    "    horizontal_flip = True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe( \n",
    "    dataframe = submission_df,\n",
    "    directory = OUTPUT_PATH + 'test_upload/',\n",
    "    x_col = \"Id\",\n",
    "    y_col = None,\n",
    "    shuffle = False,\n",
    "    class_mode = None,\n",
    "    seed = RANDOM_SEED,\n",
    "    target_size = (IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_steps = 10\n",
    "predictions = []\n",
    "\n",
    "for i in range(tta_steps):\n",
    "    preds = model.predict_generator(test_generator, steps = len(test_generator), verbose = 1) \n",
    "    predictions.append(preds)\n",
    "\n",
    "pred = np.mean(predictions, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(pred, axis = -1)\n",
    "label_map = (train_generator.class_indices)\n",
    "label_map = dict((v,k) for k,v in label_map.items())\n",
    "predictions = [label_map[k] for k in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_dir = test_generator.filenames\n",
    "submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns = ['Id', 'Category'])\n",
    "submission['Id'] = submission['Id'].replace('test_upload/','')\n",
    "submission.to_csv('submission_TTA.csv', index = False)\n",
    "print('Save submit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
