{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Идеальное решение на основе предыдущих экспериментов"},{"metadata":{},"cell_type":"markdown","source":"Из ноутбука удалены лишние строки по анализу данных и прошлых экспериментов\nчтобы уменьшить время выполнения ноутбука да и вообще самому легче ориентироваться в коротком ноутбуке\n\nИспользовать **ImageDataAugmentor** не получилось, постоянно возникали какие-то непонятные ошибки, решил настраивать генерацию руками"},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install tensorflow --upgrade\n!pip install -q efficientnet\n!pip install git+https://github.com/mjkvaak/ImageDataAugmentor","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport math\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport csv\nimport os\nimport sys\nimport zipfile\nimport shutil\n\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\n\nimport keras as keras\nimport keras.models\nimport keras.layers\nimport keras.backend\nimport keras.callbacks\n\nfrom ImageDataAugmentor.image_data_augmentor import *\nimport albumentations\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras import optimizers\nfrom keras.models import Model, Sequential\nfrom keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\nfrom keras.layers import *\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n\nfrom tensorflow.python.client import device_lib\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, KFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#увеличим дефолтный размер графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#графики в svg выглядят более четкими\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device_list = device_lib.list_local_devices()\ndevice_list_GPU = [x.name for x in device_list if 'GPU' in x.name]\nprint ('GPU подключен') if device_list_GPU else  print('GPU не подключен')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_PATH  = '../input/sf-dl-car-classification/'\nPICTURE_PATH = '/dev/shm/'\nPICTURE_SPLIT_PATH = '/dev/shm/split/'\nMODELS_PATH = '../input/sf-dl-car-classification/modelas12/'\nOUTPUT_PATH = '/kaggle/working/car/'","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"os.makedirs(PICTURE_PATH, exist_ok = True)\nos.makedirs(PICTURE_SPLIT_PATH, exist_ok = True)\n\n\nRANDOM_SEED = 42\n\nnp.random.seed(RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS       = 7\nBATCH_SIZE   = 32\nLR           = 1e-3\nEND_LR       = 1e-4\nDECAY_STEPS  = 100000\nVALID_SPLIT  = 0.2\n\nCLASS_NUM    = 10\nIMG_SIZE     = 280\nIMG_CHANNELS = 3\ninput_shape  = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nUSE_BIAS     = False\nKERNEL_REG   = 'l2'\nDROPOUT_RATE = 0.25\nEPOCHS_DROP  = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA / Анализ данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -d -r '/dev/shm/'\n#!rm -d -r '../working/car/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!unzip '../input/sf-dl-car-classification/train.zip' -d /dev/shm/\n#!unzip '../input/sf-dl-car-classification/train.zip' -d '../working/car/'\nprint('Распаковка картинок')\nwith zipfile.ZipFile(INPUT_PATH + 'train.zip',\"r\") as z:\n    z.extractall(PICTURE_PATH)\nprint('Распаковка завершена')    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(INPUT_PATH + 'train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories = train_df.Category.value_counts()\ncategories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data"},{"metadata":{},"cell_type":"markdown","source":"### Stratify Split\nприменить KFold не увенчалось успехом, так как постоянно приходилось перетасовывать изображения, что накладно, да и 3 этапа сами по себе долгие, если ещё и делить на разные комбинации, то вообще обучать будет вечность."},{"metadata":{"trusted":true},"cell_type":"code","source":"def stratify(): \n    train_files, valid_files, train_labels, valid_labels = \\\n        train_test_split(train_df['Id'], train_df['Category'], \n                         test_size = VALID_SPLIT, \n                         random_state = RANDOM_SEED, \n                         stratify = train_df['Category'])\n\n    train_files = pd.DataFrame(train_files)\n    valid_files = pd.DataFrame(valid_files)\n    train_files['Category'] = train_labels\n    valid_files['Category'] = valid_labels\n\n    print(train_files.shape, valid_files.shape)\n    return train_files, valid_files\n\ntrain_files, valid_files = stratify()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def move_files():\n    for cat in categories.index:\n        os.makedirs(f'{PICTURE_SPLIT_PATH}train/{str(cat)}')\n        os.makedirs(f'{PICTURE_SPLIT_PATH}valid/{str(cat)}') \n        \n    count_file = 0\n    for index, row in train_files.iterrows():\n        file_path = 'train/' + str(row['Category']) + '/' + str(row['Id'])\n        shutil.move(PICTURE_PATH + file_path, PICTURE_SPLIT_PATH + file_path)\n        count_file += 1\n    print(f'move {count_file} train files')\n    \n    count_file = 0\n    for index,row in valid_files.iterrows():\n        source_path = 'train/' + str(row['Category']) + '/' + str(row['Id'])\n        destination_path = 'valid/' + str(row['Category']) + '/' + str(row['Id'])\n        shutil.move(PICTURE_PATH + source_path, PICTURE_SPLIT_PATH + destination_path)\n        count_file += 1\n    print(f'move {count_file} valid files')  \n    \nmove_files()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = 0\nfor i in range(0, 10):\n    dirr = PICTURE_SPLIT_PATH + f'train/{i}/'\n    count = len([name for name in os.listdir(dirr) if os.path.isfile(os.path.join(dirr, name))])\n    print(f'{i} - ', count)\n    total += count\nprint(f'total is train {total}')\n\ntotal = 0\nfor i in range(0, 10):\n    dirr = PICTURE_SPLIT_PATH + f'valid/{i}/'\n    count = len([name for name in os.listdir(dirr) if os.path.isfile(os.path.join(dirr, name))])\n    print(f'{i} - ', count)\n    total += count\nprint(f'total is valid {total}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# для размера 380 и EfficientNetB4 получаем на последнем этапе ошибку 'OOM when allocating tensor ... by allocator GPU_0_bfc'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p_rescale = 1. / 255\np_rotation_range = 5\np_zoom_range = 0.1\np_width_shift_range = 0.1\np_height_shift_range = 0.1\np_brightness_range = [0.5, 0.1]\np_shear_range = 0.15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dataGenerators(t):    \n    if (t == 1):        \n        datagen = ImageDataGenerator(\n            rescale = p_rescale,\n            zoom_range = p_zoom_range,\n            rotation_range = p_rotation_range,\n            width_shift_range = p_width_shift_range,\n            height_shift_range = p_height_shift_range,\n            shear_range = p_shear_range,\n            horizontal_flip = True)\n    else:\n        AUGMENTATIONS = albumentations.Compose([\n            albumentations.HorizontalFlip(p = 0.5),\n            albumentations.Rotate(limit = 5, interpolation = 1, border_mode = 4, value = None, mask_value = None, always_apply = False, p = 0.5),\n            albumentations.OneOf([\n                albumentations.CenterCrop(height = 280, width = 260),\n                albumentations.CenterCrop(height = 260, width = 280),\n            ],p = 0.5),\n            albumentations.OneOf([\n                albumentations.RandomBrightnessContrast(brightness_limit = 0.3, contrast_limit = 0.3),\n                albumentations.RandomBrightnessContrast(brightness_limit = 0.1, contrast_limit = 0.1)\n            ],p = 0.5),\n            albumentations.GaussianBlur(p = 0.05),\n            albumentations.HueSaturationValue(p = 0.5),\n            albumentations.RGBShift(p = 0.5),\n            albumentations.FancyPCA(alpha = 0.1, always_apply = False, p = 0.5),\n            albumentations.Resize(IMG_SIZE, IMG_SIZE)\n        ])        \n        datagen = ImageDataAugmentor(rescale = p_rescale, augment = AUGMENTATIONS)\n        \n    return datagen\n\ndatagen = create_dataGenerators(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### datagen"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_generators():\n    train_generator = datagen.flow_from_directory(\n        PICTURE_SPLIT_PATH + 'train/',\n        target_size = (IMG_SIZE, IMG_SIZE),\n        batch_size = BATCH_SIZE,\n        class_mode = 'categorical',\n        shuffle = True, \n        seed = RANDOM_SEED)\n\n    valid_generator = datagen.flow_from_directory(\n        PICTURE_SPLIT_PATH +'valid/',\n        target_size = (IMG_SIZE, IMG_SIZE),\n        batch_size = BATCH_SIZE,\n        class_mode = 'categorical',\n        shuffle = True, \n        seed = RANDOM_SEED)\n    return train_generator, valid_generator\n\ntrain_generator, valid_generator = create_generators()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Строим модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для размера 260 используем EfficientNetB2\nbase_model = efn.EfficientNetB7(weights = 'imagenet', include_top = False, input_shape = input_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Замораживаем веса в базовой модели\nbase_model.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    # Устанавливаем новую \"голову\" (head)\n    model = Sequential()\n    model.add(base_model)\n    \n    model.add(GlobalAveragePooling2D()) # объединяем все признаки в единый вектор     \n    model.add(BatchNormalization())\n    \n    model.add(Dense(256, use_bias = USE_BIAS, kernel_regularizer = KERNEL_REG, activation = 'relu'))\n    #model.add(BatchNormalization())\n    \n    model.add(Dropout(DROPOUT_RATE))\n    model.add(Dense(CLASS_NUM, activation = 'softmax'))    \n    \n    model.summary()\n    \n    return model\n\ndef create_callbacks():\n    checkpoint = ModelCheckpoint('best_model.hdf5', monitor = 'val_accuracy', verbose = 1, mode = 'max', save_best_only = True)\n    earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, verbose = 1, patience = 3, restore_best_weights = True)    \n    def step_decay(epoch):\n        return LR * math.pow(0.9, math.floor((1 + epoch) / EPOCHS_DROP))\n    lrScheduler = LearningRateScheduler(step_decay, verbose = 1)\n    #reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.25, patience = 3, min_lr = 0.0000001, verbose = 1, mode = 'auto')\n    \n    #tbCallBack = keras.callbacks.TensorBoard(log_dir = OUTPUT_PATH + 'logs/', histogram_freq = 0, write_graph = True, write_images = False)\n    \n    return [checkpoint, earlystop, lrScheduler]\n\ncallbacks_list = create_callbacks()\n\ndef build_and_fit_model(need_load = False, step_number = ''):    \n    model = create_model()    \n    model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr = LR, amsgrad = True), metrics = [\"accuracy\"])       \n    #model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), metrics = [\"accuracy\"])\n    #model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(learning_rate = LR, rho = 0.9, epsilon = 1e-08, decay = 0.0), metrics = [\"accuracy\"])       \n    train_generator, valid_generator = create_generators()\n    if need_load:\n        history = None\n        model.load_weights(MODELS_PATH + f'model_step_{step_number}.hdf5')\n    else:        \n        history = model.fit_generator(\n            train_generator,\n            steps_per_epoch = train_generator.samples//train_generator.batch_size,\n            validation_data = valid_generator, \n            validation_steps = valid_generator.samples//valid_generator.batch_size,\n            epochs = EPOCHS,\n            callbacks = callbacks_list\n        )\n    return history, model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history, model = build_and_fit_model(False, step_number = '1')\n\n#model.save('model_step_1.hdf5')\n\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def calc_scores():\n    return model.evaluate_generator(valid_generator, steps = len(valid_generator), verbose = 1)\n\nscores = calc_scores()\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_fig():\n    if history == None:\n        return\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs_fig = range(len(acc))\n\n    plt.plot(epochs_fig, acc, 'g', label = 'Training acc')\n    plt.plot(epochs_fig, val_acc, 'r', label = 'Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    plt.figure()\n\n    plt.plot(epochs_fig, loss, 'g', label = 'Training loss')\n    plt.plot(epochs_fig, val_loss, 'r', label = 'Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()\n    \ndraw_fig()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Этап 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS       = 10\nBATCH_SIZE   = 16\nLR           = 1e-4\nEND_LR       = 1e-5\nDECAY_STEPS  = 100000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\n# Замораживаем половину базовой модели\nfine_tune_at = len(base_model.layers) // 2\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history, model = build_and_fit_model(False, step_number = '2')\n\n#model.save('model_step_2.hdf5')\n\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = calc_scores()\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_fig()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Этап 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS       = 12\nBATCH_SIZE   = 10\nLR           = 1e-5\nEND_LR       = 1e-6\nDECAY_STEPS  = 100000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Размораживаем всю базовую модель\nfor layer in base_model.layers:\n    #if not isinstance(layer, BatchNormalization): \n    layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history, model = build_and_fit_model(False, step_number = '3')\n\n#model.save('model_step_3.hdf5')\n\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = calc_scores()\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_fig()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -d -r '/dev/shm/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_cnn():\n    model = Sequential()\n\n    # Add convolutional layer consisting of 32 filters and shape of 3x3 with ReLU activation\n    # We want to preserve more information for following layers so we use padding\n    # 'Same' padding tries to pad evenly left and right, \n    # but if the amount of columns to be added is odd, it will add the extra column to the right\n    model.add(Conv2D(280, kernel_size = (3,3), activation='relu', input_shape = input_shape))\n    model.add(BatchNormalization())\n    model.add(Conv2D(280, kernel_size = (3,3), activation='relu'))\n    model.add(BatchNormalization())\n\n    # Add convolutional layer consisting of 32 filters and shape of 5x5 with ReLU activation\n    # We give strides=2 for space between each sample on the pixel grid\n    model.add(Conv2D(280, kernel_size = (5,5), strides=2, padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    # Dropping %40 of neurons\n    model.add(Dropout(0.4))\n    \n    model.add(Conv2D(64, kernel_size = (3,3), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size = (3,3), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size = (5,5), strides=2, padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n    model.add(BatchNormalization())\n    # To be able to merge into fully connected layer we have to flatten\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    \n    # Lets add softmax activated neurons as much as number of classes\n    model.add(Dense(CLASS_NUM, activation = \"softmax\"))\n    \n    # Compile the model with loss and metrics\n    model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr = learning_rate_fn, amsgrad = True), metrics = [\"accuracy\"])       \n    \n    return model\n\nmodels = []\n#models.append(model_cnn())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"#!unzip '../input/sf-dl-car-classification/test.zip' -d '../working/car/'\nprint('Распаковка картинок')\nwith zipfile.ZipFile(INPUT_PATH + 'test.zip',\"r\") as z:\n    z.extractall(PICTURE_SPLIT_PATH)\nprint('Распаковка завершена')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv(INPUT_PATH + 'sample-submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_sub(pred, train_generator, test_generator):\n    predictions = np.argmax(pred, axis = -1)\n    label_map = (train_generator.class_indices)\n    label_map = dict((v,k) for k,v in label_map.items())\n    predictions = [label_map[k] for k in predictions]\n    \n    filenames_with_dir = test_generator.filenames\n    submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns = ['Id', 'Category'])\n    submission['Id'] = submission['Id'].replace('test_upload/','')\n    submission.to_csv('submission_TTA.csv', index = False)\n    submission.head()\n    print('Save submit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sub():\n    test_generator = datagen.flow_from_dataframe(\n        dataframe = submission_df,\n        directory = PICTURE_SPLIT_PATH + 'test_upload/',\n        x_col = 'Id',\n        y_col = None,\n        shuffle = False,\n        class_mode = None,\n        seed = RANDOM_SEED,\n        target_size = (IMG_SIZE, IMG_SIZE),\n        batch_size = BATCH_SIZE)\n    \n    test_generator.reset()\n    predictions = model.predict_generator(test_generator, steps=len(test_generator), verbose=1) \n    \n    save_sub(predictions, train_generator, test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sub_tta():        \n    test_generator = datagen.flow_from_dataframe( \n        dataframe = submission_df,\n        directory = PICTURE_SPLIT_PATH + 'test_upload/',\n        x_col = \"Id\",\n        y_col = None,\n        shuffle = False,\n        class_mode = None,\n        seed = RANDOM_SEED,\n        target_size = (IMG_SIZE, IMG_SIZE),\n        batch_size = BATCH_SIZE)\n            \n    tta_steps = 10\n    predictions = []\n    models = []\n\n    for i in range(tta_steps):\n        #models[i].predict(test_generator, steps = len(test_generator), verbose = 1) \n        preds = model.predict(test_generator, steps = len(test_generator), verbose = 1) \n        predictions.append(preds)\n\n    predictions = np.mean(predictions, axis = 0)\n    \n    save_sub(predictions, train_generator, test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_tta()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = os.listdir(\"/kaggle/working\")\n\nfor filename in files:\n    print(filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}